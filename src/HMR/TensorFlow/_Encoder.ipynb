{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Encoder</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ResNet-50 network is used for encoding the image, pretrained on the ImageNet classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers.initializers import variance_scaling_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_resnet(x, is_training=True, weight_decay=0.001, reuse=False):\n",
    "    \"\"\"\n",
    "    Resnet v2-50\n",
    "    Assumes input is [batch, height_in, width_in, channels]!!\n",
    "    Input:\n",
    "    - x: N x H x W x 3\n",
    "    - weight_decay: float\n",
    "    - reuse: bool->True if test\n",
    "\n",
    "    Outputs:\n",
    "    - cam: N x 3\n",
    "    - Pose vector: N x 72\n",
    "    - Shape vector: N x 10\n",
    "    - variables: tf variables\n",
    "    \"\"\"\n",
    "    from tensorflow.contrib.slim.python.slim.nets import resnet_v2\n",
    "    # with tf.name_scope(\"Encoder_resnet\", [x]):\n",
    "    with tf.name_scope(\"Encoder_resnet\"):\n",
    "        with slim.arg_scope(resnet_v2.resnet_arg_scope(weight_decay=weight_decay)):\n",
    "            net, end_points = resnet_v2.resnet_v2_50(\n",
    "                x,\n",
    "                num_classes=None,\n",
    "                is_training=is_training,\n",
    "                reuse=reuse,\n",
    "                scope='resnet_v2_50')\n",
    "            net = tf.squeeze(net, axis=[1, 2])\n",
    "    variables = tf.contrib.framework.get_variables('resnet_v2_50')\n",
    "    return net, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_fc3_dropout(x,\n",
    "                        num_output=85,\n",
    "                        is_training=True,\n",
    "                        reuse=False,\n",
    "                        name=\"3D_module\"):\n",
    "    \"\"\"\n",
    "    3D inference module. 3 MLP layers (last is the output)\n",
    "    With dropout  on first 2.\n",
    "    Input:\n",
    "    - x: N x [|img_feat|, |3D_param|]\n",
    "    - reuse: bool\n",
    "\n",
    "    Outputs:\n",
    "    - 3D params: N x num_output\n",
    "      if orthogonal: \n",
    "           either 85: (3 + 24*3 + 10) or 109 (3 + 24*4 + 10) for factored axis-angle representation\n",
    "      if perspective:\n",
    "          86: (f, tx, ty, tz) + 24*3 + 10, or 110 for factored axis-angle.\n",
    "    - variables: tf variables\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        print('Reuse is on!')\n",
    "    with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "        net = slim.fully_connected(x, 1024, scope='fc1')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout1')\n",
    "        net = slim.fully_connected(net, 1024, scope='fc2')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout2')\n",
    "        small_xavier = variance_scaling_initializer(\n",
    "            factor=.01, mode='FAN_AVG', uniform=True)\n",
    "        net = slim.fully_connected(\n",
    "            net,\n",
    "            num_output,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=small_xavier,\n",
    "            scope='fc3')\n",
    "\n",
    "    variables = tf.contrib.framework.get_variables(scope)\n",
    "    return net, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_fn_separate(model_type):\n",
    "    \"\"\"\n",
    "    Retrieves diff encoder fn for image and 3D\n",
    "    \"\"\"\n",
    "    encoder_fn = None\n",
    "    threed_fn = None\n",
    "    if 'resnet' in model_type:\n",
    "        encoder_fn = Encoder_resnet\n",
    "    else:\n",
    "        print('Unknown encoder %s!' % model_type)\n",
    "        exit(1)\n",
    "\n",
    "    if 'fc3_dropout' in model_type:\n",
    "        threed_fn = Encoder_fc3_dropout\n",
    "\n",
    "    if encoder_fn is None or threed_fn is None:\n",
    "        print('Dont know what encoder to use for %s' % model_type)\n",
    "        import ipdb\n",
    "        ipdb.set_trace()\n",
    "\n",
    "    return encoder_fn, threed_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "During training, we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_enc_fn, threed_enc_fn = get_encoder_fn_separate('resnet_fc3_dropout')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use encoder to obtain code of input image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from src.util import image as img_util\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, json_path=None):\n",
    "    img = io.imread(img_path)\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "\n",
    "    if json_path is None:\n",
    "        if np.max(img.shape[:2]) != 224:\n",
    "            print('Resizing so the max image size is %d..' % 224)\n",
    "            scale = (float(224) / np.max(img.shape[:2]))\n",
    "        else:\n",
    "            scale = 1.\n",
    "        center = np.round(np.array(img.shape[:2]) / 2).astype(int)\n",
    "        # image center in (x,y)\n",
    "        center = center[::-1]\n",
    "    else:\n",
    "        scale, center = op_util.get_bbox(json_path)\n",
    "\n",
    "    crop, proc_param = img_util.scale_and_crop(img, scale, center, 224)\n",
    "\n",
    "    # Normalize image to [-1, 1]\n",
    "    crop = 2 * ((crop / 255.) - 0.5)\n",
    "\n",
    "    return crop, proc_param, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing so the max image size is 224..\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/im1963.jpg'\n",
    "json_path = None\n",
    "input_img, proc_param, img = preprocess_image(img_path, json_path)\n",
    "input_img = np.expand_dims(input_img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_img.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.float32(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image features.\n",
    "img_feat, E_var = img_enc_fn(input_img, is_training=False, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# E_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Encoder_resnet/Squeeze:0' shape=(1, 2048) dtype=float32>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_feat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ResNet output is average pooled, producing features $Ï† \\in R^{2048}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
