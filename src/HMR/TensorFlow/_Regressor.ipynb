{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Regression</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3D regression module consists of two fully-connected layers with 1024 neurons each with a dropout layer in between, followed by a final layer of 85D neurons. We use T = 3 iterations for all of our experiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers.initializers import variance_scaling_initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_resnet(x, is_training=True, weight_decay=0.001, reuse=False):\n",
    "    \"\"\"\n",
    "    Resnet v2-50\n",
    "    Assumes input is [batch, height_in, width_in, channels]!!\n",
    "    Input:\n",
    "    - x: N x H x W x 3\n",
    "    - weight_decay: float\n",
    "    - reuse: bool->True if test\n",
    "\n",
    "    Outputs:\n",
    "    - cam: N x 3\n",
    "    - Pose vector: N x 72\n",
    "    - Shape vector: N x 10\n",
    "    - variables: tf variables\n",
    "    \"\"\"\n",
    "    from tensorflow.contrib.slim.python.slim.nets import resnet_v2\n",
    "    # with tf.name_scope(\"Encoder_resnet\", [x]):\n",
    "    with tf.name_scope(\"Encoder_resnet\"):\n",
    "        with slim.arg_scope(resnet_v2.resnet_arg_scope(weight_decay=weight_decay)):\n",
    "            net, end_points = resnet_v2.resnet_v2_50(\n",
    "                x,\n",
    "                num_classes=None,\n",
    "                is_training=is_training,\n",
    "                reuse=reuse,\n",
    "                scope='resnet_v2_50')\n",
    "            net = tf.squeeze(net, axis=[1, 2])\n",
    "    variables = tf.contrib.framework.get_variables('resnet_v2_50')\n",
    "    return net, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_fc3_dropout(x,\n",
    "                        num_output=85,\n",
    "                        is_training=True,\n",
    "                        reuse=False,\n",
    "                        name=\"3D_module\"):\n",
    "    \"\"\"\n",
    "    3D inference module. 3 MLP layers (last is the output)\n",
    "    With dropout  on first 2.\n",
    "    Input:\n",
    "    - x: N x [|img_feat|, |3D_param|]\n",
    "    - reuse: bool\n",
    "\n",
    "    Outputs:\n",
    "    - 3D params: N x num_output\n",
    "      if orthogonal: \n",
    "           either 85: (3 + 24*3 + 10) or 109 (3 + 24*4 + 10) for factored axis-angle representation\n",
    "      if perspective:\n",
    "          86: (f, tx, ty, tz) + 24*3 + 10, or 110 for factored axis-angle.\n",
    "    - variables: tf variables\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        print('Reuse is on!')\n",
    "    with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "        net = slim.fully_connected(x, 1024, scope='fc1')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout1')\n",
    "        net = slim.fully_connected(net, 1024, scope='fc2')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout2')\n",
    "        small_xavier = variance_scaling_initializer(\n",
    "            factor=.01, mode='FAN_AVG', uniform=True)\n",
    "        net = slim.fully_connected(\n",
    "            net,\n",
    "            num_output,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=small_xavier,\n",
    "            scope='fc3')\n",
    "\n",
    "    variables = tf.contrib.framework.get_variables(scope)\n",
    "    return net, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_encoder_fn_separate(model_type):\n",
    "    \"\"\"\n",
    "    Retrieves diff encoder fn for image and 3D\n",
    "    \"\"\"\n",
    "    encoder_fn = None\n",
    "    threed_fn = None\n",
    "    if 'resnet' in model_type:\n",
    "        encoder_fn = Encoder_resnet\n",
    "    else:\n",
    "        print('Unknown encoder %s!' % model_type)\n",
    "        exit(1)\n",
    "\n",
    "    if 'fc3_dropout' in model_type:\n",
    "        threed_fn = Encoder_fc3_dropout\n",
    "\n",
    "    if encoder_fn is None or threed_fn is None:\n",
    "        print('Dont know what encoder to use for %s' % model_type)\n",
    "        import ipdb\n",
    "        ipdb.set_trace()\n",
    "\n",
    "    return encoder_fn, threed_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_enc_fn, threed_enc_fn = get_encoder_fn_separate('resnet_fc3_dropout')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from src.util import image as img_util\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(img_path, json_path=None):\n",
    "    img = io.imread(img_path)\n",
    "    if img.shape[2] == 4:\n",
    "        img = img[:, :, :3]\n",
    "\n",
    "    if json_path is None:\n",
    "        if np.max(img.shape[:2]) != 224:\n",
    "            print('Resizing so the max image size is %d..' % 224)\n",
    "            scale = (float(224) / np.max(img.shape[:2]))\n",
    "        else:\n",
    "            scale = 1.\n",
    "        center = np.round(np.array(img.shape[:2]) / 2).astype(int)\n",
    "        # image center in (x,y)\n",
    "        center = center[::-1]\n",
    "    else:\n",
    "        scale, center = op_util.get_bbox(json_path)\n",
    "\n",
    "    crop, proc_param = img_util.scale_and_crop(img, scale, center, 224)\n",
    "\n",
    "    # Normalize image to [-1, 1]\n",
    "    crop = 2 * ((crop / 255.) - 0.5)\n",
    "\n",
    "    return crop, proc_param, img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing so the max image size is 224..\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/im1963.jpg'\n",
    "json_path = None\n",
    "input_img, proc_param, img = preprocess_image(img_path, json_path)\n",
    "input_img = np.expand_dims(input_img, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = np.float32(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract image features.\n",
    "img_feat, E_var = img_enc_fn(input_img, is_training=False, reuse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flags.DEFINE_integer('num_stage', 3, '# of times to iterate regressor')\n",
    "num_stage = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "curr_path = osp.dirname(os.getcwd())\n",
    "model_dir = osp.join(curr_path, '..', 'models')\n",
    "\n",
    "# SMPL_MODEL_PATH = osp.join(model_dir, 'neutral_smpl_with_cocoplus_reg.pkl')\n",
    "# SMPL_FACE_PATH = osp.join(curr_path, '../src/tf_smpl', 'smpl_faces.npy')\n",
    "\n",
    "# smpl_model_path = SMPL_MODEL_PATH\n",
    "# smpl_face_path = SMPL_FACE_PATH\n",
    "\n",
    "smpl_model_path = r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\models\\neutral_smpl_with_cocoplus_reg.pkl'\n",
    "smpl_face_path = r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\src\\tf_smpl\\smpl_faces.npy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deepdish as dd\n",
    "from os.path import join, dirname\n",
    "def load_mean_param():\n",
    "    mean = np.zeros((1, 85))\n",
    "    # Initialize scale at 0.9\n",
    "    mean[0, 0] = 0.9\n",
    "    mean_path = join(\n",
    "        dirname(smpl_model_path), 'neutral_smpl_mean_params.h5')\n",
    "    mean_vals = dd.io.load(mean_path)\n",
    "\n",
    "    mean_pose = mean_vals['pose']\n",
    "    # Ignore the global rotation.\n",
    "    mean_pose[:3] = 0.\n",
    "    mean_shape = mean_vals['shape']\n",
    "\n",
    "    # This initializes the global pose to be up-right when projected\n",
    "    mean_pose[0] = np.pi\n",
    "\n",
    "    mean[0, 3:] = np.hstack((mean_pose, mean_shape))\n",
    "    mean = tf.constant(mean, tf.float32)\n",
    "    mean_var = tf.Variable(\n",
    "        mean, name=\"mean_param\", dtype=tf.float32, trainable=True)\n",
    "    E_var.append(mean_var)\n",
    "    init_mean = tf.tile(mean_var, [1, 1])\n",
    "    return init_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.tf_smpl.batch_lbs import batch_rodrigues\n",
    "from src.tf_smpl.batch_smpl import SMPL\n",
    "from src.tf_smpl.projection import batch_orth_proj_idrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl = SMPL(smpl_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Encoder_resnet/Squeeze:0' shape=(1, 2048) dtype=float32>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'Tile:0' shape=(1, 85) dtype=float32>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_prev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0216 15:30:16.864979  4980 deprecation.py:323] From C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\src\\tf_smpl\\batch_lbs.py:55: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "num_cam=3\n",
    "num_theta=72\n",
    "loss_kps = []\n",
    "# if self.use_3d_label:\n",
    "#     loss_3d_joints, loss_3d_params = [], []\n",
    "# For discriminator\n",
    "fake_rotations, fake_shapes = [], []\n",
    "# Start loop\n",
    "# 85D\n",
    "theta_prev = load_mean_param()\n",
    "\n",
    "# For visualizations\n",
    "all_verts = []\n",
    "all_pred_kps = []\n",
    "all_pred_cams = []\n",
    "all_delta_thetas = []\n",
    "all_theta_prev = []\n",
    "\n",
    "num_stage = 1\n",
    "\n",
    "# Main IEF loop\n",
    "for i in np.arange(num_stage):\n",
    "    print('Iteration %d' % i)\n",
    "    # ---- Compute outputs\n",
    "    state = tf.concat([img_feat, theta_prev], 1)\n",
    "\n",
    "    if i == 0:\n",
    "        delta_theta, threeD_var = threed_enc_fn(\n",
    "            state, num_output=85, reuse=False)\n",
    "        E_var.extend(threeD_var)\n",
    "    else:\n",
    "        delta_theta, _ = threed_enc_fn(\n",
    "            state, num_output=85, reuse=True)\n",
    "\n",
    "    # Compute new theta\n",
    "    theta_here = theta_prev + delta_theta\n",
    "    # cam = N x 3, pose N x self.num_theta, shape: N x 10\n",
    "    cams = theta_here[:, : num_cam]\n",
    "    poses = theta_here[:, num_cam:(num_cam + num_theta)]\n",
    "    shapes = theta_here[:, (num_cam + num_theta):]\n",
    "    \n",
    "    # Rs_wglobal is Nx24x3x3 rotation matrices of poses\n",
    "    verts, Js, pred_Rs = smpl(shapes, poses, get_skin=True)\n",
    "    pred_kp = batch_orth_proj_idrot(\n",
    "        Js, cams, name='proj2d_stage%d' % i)\n",
    "#     # --- Compute losses:\n",
    "#     loss_kps.append(self.e_loss_weight * self.keypoint_loss(\n",
    "#         self.kp_loader, pred_kp))\n",
    "#     pred_Rs = tf.reshape(pred_Rs, [-1, 24, 9])\n",
    "#     if self.use_3d_label:\n",
    "#         loss_poseshape, loss_joints = self.get_3d_loss(\n",
    "#             pred_Rs, shapes, Js)\n",
    "#         loss_3d_params.append(loss_poseshape)\n",
    "#         loss_3d_joints.append(loss_joints)\n",
    "\n",
    "#     # Save pred_rotations for Discriminator\n",
    "#     fake_rotations.append(pred_Rs[:, 1:, :])\n",
    "#     fake_shapes.append(shapes)\n",
    "\n",
    "#     # Save things for visualiations:\n",
    "#     self.all_verts.append(tf.gather(verts, self.show_these))\n",
    "#     self.all_pred_kps.append(tf.gather(pred_kp, self.show_these))\n",
    "#     self.all_pred_cams.append(tf.gather(cams, self.show_these))\n",
    "\n",
    "    # Finally update to end iteration.\n",
    "    theta_prev = theta_here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'smpl_main/strided_slice_3:0' shape=(1, 6890, 3) dtype=float32>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'proj2d_stage0/Reshape_1:0' shape=(1, 19, 2) dtype=float32>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'smpl_main/Reshape_2:0' shape=(1, 24, 3, 3) dtype=float32>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_Rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
