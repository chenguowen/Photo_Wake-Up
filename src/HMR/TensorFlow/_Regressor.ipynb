{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "from tensorflow.contrib.layers.python.layers.initializers import variance_scaling_initializer\n",
    "\n",
    "import skimage.io as io\n",
    "import numpy as np\n",
    "from src.util import image as img_util\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import deepdish as dd\n",
    "from os.path import join, dirname\n",
    "\n",
    "from utilsTest import *\n",
    "\n",
    "import os.path as osp\n",
    "import os\n",
    "import sys\n",
    "curr_path = osp.dirname(os.getcwd())\n",
    "model_dir = osp.join(curr_path, '..', 'models')\n",
    "\n",
    "smpl_model_path = r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\models\\neutral_smpl_with_cocoplus_reg.pkl'\n",
    "smpl_face_path = r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\src\\tf_smpl\\smpl_faces.npy'\n",
    "\n",
    "from src.tf_smpl.batch_lbs import batch_rodrigues\n",
    "from src.tf_smpl.batch_smpl import SMPL\n",
    "from src.tf_smpl.projection import batch_orth_proj_idrot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resizing so the max image size is 224..\n"
     ]
    }
   ],
   "source": [
    "img_path = 'data/im1963.jpg'\n",
    "json_path = None\n",
    "input_img, proc_param, img = preprocess_image(img_path, json_path)\n",
    "input_img = np.expand_dims(input_img, 0)\n",
    "input_img = np.float32(input_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mean_param():\n",
    "    mean = np.zeros((1, 85))\n",
    "    # Initialize scale at 0.9\n",
    "    mean[0, 0] = 0.9\n",
    "    mean_path = join(\n",
    "        dirname(smpl_model_path), 'neutral_smpl_mean_params.h5')\n",
    "    mean_vals = dd.io.load(mean_path)\n",
    "\n",
    "    mean_pose = mean_vals['pose']\n",
    "    # Ignore the global rotation.\n",
    "    mean_pose[:3] = 0.\n",
    "    mean_shape = mean_vals['shape']\n",
    "\n",
    "    # This initializes the global pose to be up-right when projected\n",
    "    mean_pose[0] = np.pi\n",
    "\n",
    "    mean[0, 3:] = np.hstack((mean_pose, mean_shape))\n",
    "    mean = tf.constant(mean, tf.float32)\n",
    "    mean_var = tf.Variable(\n",
    "        mean, name=\"mean_param\", dtype=tf.float32, trainable=True)\n",
    "    E_var.append(mean_var)\n",
    "    init_mean = tf.tile(mean_var, [1, 1])\n",
    "    return init_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Encoder_fc3_dropout(x,\n",
    "                        num_output=85,\n",
    "                        is_training=True,\n",
    "                        reuse=False,\n",
    "                        name=\"3D_module\"):\n",
    "    \"\"\"\n",
    "    3D inference module. 3 MLP layers (last is the output)\n",
    "    With dropout  on first 2.\n",
    "    Input:\n",
    "    - x: N x [|img_feat|, |3D_param|]\n",
    "    - reuse: bool\n",
    "\n",
    "    Outputs:\n",
    "    - 3D params: N x num_output\n",
    "      if orthogonal: \n",
    "           either 85: (3 + 24*3 + 10) or 109 (3 + 24*4 + 10) for factored axis-angle representation\n",
    "      if perspective:\n",
    "          86: (f, tx, ty, tz) + 24*3 + 10, or 110 for factored axis-angle.\n",
    "    - variables: tf variables\n",
    "    \"\"\"\n",
    "    if reuse:\n",
    "        print('Reuse is on!')\n",
    "    with tf.variable_scope(name, reuse=reuse) as scope:\n",
    "        net = slim.fully_connected(x, 1024, scope='fc1')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout1')\n",
    "        net = slim.fully_connected(net, 1024, scope='fc2')\n",
    "        net = slim.dropout(net, 0.5, is_training=is_training, scope='dropout2')\n",
    "        small_xavier = variance_scaling_initializer(\n",
    "            factor=.01, mode='FAN_AVG', uniform=True)\n",
    "        net = slim.fully_connected(\n",
    "            net,\n",
    "            num_output,\n",
    "            activation_fn=None,\n",
    "            weights_initializer=small_xavier,\n",
    "            scope='fc3')\n",
    "\n",
    "    variables = tf.contrib.framework.get_variables(scope)\n",
    "    return net, variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_3d_label = True\n",
    "num_stage = 3\n",
    "total_params = 85\n",
    "num_cam = 3\n",
    "num_theta = 72\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0227 23:30:37.343826 16076 deprecation.py:323] From C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\src\\tf_smpl\\batch_lbs.py:55: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1\n",
      "Reuse is on!\n",
      "Iteration 2\n",
      "Reuse is on!\n"
     ]
    }
   ],
   "source": [
    "# img_enc_fn, threed_enc_fn = get_encoder_fn_separate('resnet_fc3_dropout')\n",
    "# img_feat, E_var = img_enc_fn(input_img, is_training=False, reuse=False)\n",
    "img_feat, E_var = Encoder_resnet(input_img, is_training=False, reuse=False)\n",
    "smpl = SMPL(smpl_model_path)\n",
    "\n",
    "loss_kps = []\n",
    "if use_3d_label:\n",
    "    loss_3d_joints, loss_3d_params = [], []\n",
    "# For discriminator\n",
    "fake_rotations, fake_shapes = [], []\n",
    "# Start loop\n",
    "# 85D\n",
    "theta_prev = load_mean_param()\n",
    "\n",
    "# For visualizations\n",
    "all_verts = []\n",
    "all_pred_kps = []\n",
    "all_pred_cams = []\n",
    "all_delta_thetas = []\n",
    "all_theta_prev = []\n",
    "\n",
    "# Main IEF loop\n",
    "for i in np.arange(num_stage):\n",
    "    print('Iteration %d' % i)\n",
    "    # ---- Compute outputs\n",
    "    state = tf.concat([img_feat, theta_prev], 1)\n",
    "\n",
    "    if i == 0:\n",
    "#         delta_theta, _ = threed_enc_fn(state, num_output= total_params, reuse=False)\n",
    "        delta_theta, _ = Encoder_fc3_dropout(state, num_output= total_params, reuse=False)\n",
    "    else:\n",
    "#         delta_theta, _ = threed_enc_fn(state, num_output= total_params, reuse=True)\n",
    "        delta_theta, _ = Encoder_fc3_dropout(state, num_output= total_params, reuse=True)\n",
    "\n",
    "    # Compute new theta\n",
    "    theta_here = theta_prev + delta_theta\n",
    "    # cam = N x 3, pose N x self.num_theta, shape: N x 10\n",
    "    cams = theta_here[:, :num_cam]\n",
    "    poses = theta_here[:, num_cam:(num_cam + num_theta)]\n",
    "    shapes = theta_here[:, (num_cam + num_theta):]\n",
    "    # Rs_wglobal is Nx24x3x3 rotation matrices of poses\n",
    "    verts, Js, pred_Rs = smpl(shapes, poses, get_skin=True)\n",
    "    pred_kp = batch_orth_proj_idrot(Js, cams, name='proj2d_stage%d' % i)\n",
    "    # --- Compute losses:\n",
    "#     loss_kps.append(keypoint_loss(\n",
    "#         self.kp_loader, pred_kp))\n",
    "    pred_Rs = tf.reshape(pred_Rs, [-1, 24, 9])\n",
    "#     if self.use_3d_label:\n",
    "#         loss_poseshape, loss_joints = self.get_3d_loss(\n",
    "#             pred_Rs, shapes, Js)\n",
    "#         loss_3d_params.append(loss_poseshape)\n",
    "#         loss_3d_joints.append(loss_joints)\n",
    "\n",
    "    # Save pred_rotations for Discriminator\n",
    "    fake_rotations.append(pred_Rs[:, 1:, :])\n",
    "    fake_shapes.append(shapes)\n",
    "\n",
    "    # Finally update to end iteration.\n",
    "    theta_prev = theta_here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'strided_slice_3:0' shape=(1, 23, 9) dtype=float32>,\n",
       " <tf.Tensor 'strided_slice_7:0' shape=(1, 23, 9) dtype=float32>,\n",
       " <tf.Tensor 'strided_slice_11:0' shape=(1, 23, 9) dtype=float32>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_rotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'strided_slice_2:0' shape=(1, 10) dtype=float32>,\n",
       " <tf.Tensor 'strided_slice_6:0' shape=(1, 10) dtype=float32>,\n",
       " <tf.Tensor 'strided_slice_10:0' shape=(1, 10) dtype=float32>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_shapes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
