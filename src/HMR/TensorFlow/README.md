# End-to-end Recovery of Human Shape and Pose![Teaser Image](https://akanazawa.github.io/hmr/resources/images/teaser.png)### Requirements- Python 2.7- [TensorFlow](https://www.tensorflow.org/) tested on version 1.3, demo alone runs with TF 1.12### Installation#### Linux Setup with virtualenv```virtualenv venv_hmrsource venv_hmr/bin/activatepip install -U pipdeactivatesource venv_hmr/bin/activatepip install -r requirements.txt```#### Install TensorFlowWith GPU:```pip install tensorflow-gpu==1.3.0```Without GPU:```pip install tensorflow==1.3.0```### Windows Setup with python 3 and AnacondaThis is only partialy tested.```conda env create -f hmr.yml```### Demo1. Download the pre-trained models```wget https://people.eecs.berkeley.edu/~kanazawa/cachedir/hmr/models.tar.gz && tar -xf models.tar.gz```2. Run the demo```python -m demo --img_path data/coco1.pngpython -m demo --img_path data/im1954.jpg```Images should be tightly cropped, where the height of the person is roughly 150px.On images that are not tightly cropped, you can run[openpose](https://github.com/CMU-Perceptual-Computing-Lab/openpose) and supplyits output json (run it with `--write_json` option).When json_path is specified, the demo will compute the right scale and bbox center to run HMR:```python -m demo --img_path data/random.jpg --json_path data/random_keypoints.json```(The demo only runs on the most confident bounding box, see `src/util/openpose.py:get_bbox`)### Webcam Demo1. Download pre-trained models like above.2. Run webcam Demo2. Run the demo```python -m demo --img_path data/coco1.pngpython -m demo --img_path data/im1954.jpg```<img alt="bvh" src="https://i.imgur.com/QxML83b.gif" /><img alt="" src="https://i.imgur.com/vfge7DS.gif" /><img alt="bvh2" src=https://i.imgur.com/UvBM1gv.gif />