{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Datasets Details</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lsp (Leeds Sports Pose)\n",
    "\n",
    "This dataset contains 2000 pose annotated images of mostly sports people. The images have been scaled such that the most prominent person is roughly 150 pixels in length. Each image has been annotated with 14 joint locations. In paper the dataset was split into two parts for training and testing. The first 1000 images (im0001.jpg to im1000.jpg) were used for training and strictly ALL parameter selection. The second 1000 images (im1001.jpg to im2000.jpg) were used for testing. The ordering of the joints is as follows:\n",
    "\n",
    "1. Right ankle (կոճ)\n",
    "2. Right knee (ծունկ)\n",
    "3. Right hip (ազդր)\n",
    "4. Left hip\n",
    "5. Left knee\n",
    "6. Left ankle\n",
    "7. Right wrist (դաստակ)\n",
    "8. Right elbow (արմունկ)\n",
    "9. Right shoulder (ուս)\n",
    "10. Left shoulder\n",
    "11. Left elbow\n",
    "12. Left wrist\n",
    "13. Neck (պարանոց)\n",
    "14. Head top (գլուխ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lsp_ext (Leeds Sports Pose Extended)\n",
    "\n",
    "This dataset contains 10,000 images gathered from Flickr searches for the tags 'parkour', 'gymnastics', and 'athletics' and consists of poses deemed to be challenging to estimate. Each image has a corresponding annotation gathered from Amazon Mechanical Turk and as such cannot be guaranteed to be highly accurate. The images have been scaled such that the annotated person is roughly 150 pixels in length. Each image has been annotated with up to 14 visible joint locations. The ordering of the joints is the same as of lsp."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mpii\n",
    "\n",
    "The dataset includes around 25K images containing over 40K people with annotated body joints. Overall the dataset covers 410 human activities and each image is provided with an activity label. Each image was extracted from a YouTube video and provided with preceding and following un-annotated frames. In addition, for the test set we obtained richer annotations including body part occlusions and 3D torso and head orientations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## coco\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## h36m\n",
    "\n",
    "3.6 Million accurate 3D Human poses, acquired by recording the performance of 5 female and 6 male subjects, under 4 different viewpoints. We have reserved 7 subjects, 3 female and 4 male, for training and validation, and 4 subjects (2 female and 2 male) for testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: DeprecationWarning: `imread` is deprecated!\n",
      "`imread` is deprecated in SciPy 1.0.0, and will be removed in 1.2.0.\n",
      "Use ``imageio.imread`` instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import scipy.misc\n",
    "from matplotlib import pyplot as plt\n",
    "mat = scipy.io.loadmat(r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\datasets\\lsp\\joints.mat')\n",
    "image = scipy.misc.imread(r'C:\\_Files\\MyProjects\\ASDS_3\\Photo_Wake-Up\\src\\HMR\\TensorFlow\\datasets\\lsp\\images\\im0001.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 14, 2000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat['joints'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints = mat['joints'][:, :, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 29.74645941,  30.5501068 ,  28.94281202,  43.00664135,\n",
       "         42.20299396,  42.60481765,  24.52275137,  15.28080638,\n",
       "         24.12092767,  50.64129155,  52.65041003,  53.85588112,\n",
       "         38.184757  ,  38.9884044 ],\n",
       "       [143.34544031, 117.22690013,  84.67918082,  85.08100452,\n",
       "        111.1995447 , 132.89802424,  52.9351089 ,  62.98070128,\n",
       "         42.08586913,  44.09498761,  58.96246433,  58.96246433,\n",
       "         36.05851371,  15.56550525],\n",
       "       [  0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ,   0.        ,   0.        ,\n",
       "          0.        ,   0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joints"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
