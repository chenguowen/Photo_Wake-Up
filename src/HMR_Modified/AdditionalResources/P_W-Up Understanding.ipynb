{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div align=\"center\">Detail understanding of Photo Wake-Up paper</div>\n",
    "---------------------------------------------------------------------\n",
    "\n",
    "you can Find me on Github:\n",
    "> ###### [ GitHub](https://github.com/lev1khachatryan)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a method for animating a human subject from a single photo. E.g., the ***character can walk out, run, sit, or jump in 3D***. The key contributions are: \n",
    "\n",
    "1. an application of viewing and animating humans in single photos in 3D\n",
    "\n",
    "\n",
    "2. a novel 2D warping method to deform a posable template body model to fit the person’s complex silhouette to create an animatable mesh, and \n",
    "\n",
    "\n",
    "3. a method for handling partial self occlusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our operating range on input and output is as follows. The person should be shown in whole (full body photo) as a fairly frontal view. The system is the first to enable 3D animation of a clothed subject from a single image. Model supports partial occlusion, specifically of arms in front of the body. While we aim for a mesh that is sufficient for convincing animation, we do not guarantee a metrically correct 3D mesh, due to the inherent ambiguity in reconstructing a 3D model from 2D input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div align=\"center\">Model</div>\n",
    "---------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='_assets/P_W-Up/architecture.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Figure 2:*** Overview of our method. Given a photo, person detection, 2D pose estimation, and person segmentation, is\n",
    "performed using off-the-shelf algorithms. Then, A SMPL template model is fit to the 2D pose and projected into the image\n",
    "as a normal map and a skinning map. The ***core of system is:*** find a mapping between person’s silhouette and the SMPL\n",
    "silhouette, warp the SMPL normal/skinning maps to the output, and build a depth map by integrating the warped normal\n",
    "map. This process is repeated to simulate the model’s back view and combine depth and skinning maps to create a complete,\n",
    "rigged 3D mesh. The mesh is further textured, and animated using motion capture sequences on an inpainted background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
